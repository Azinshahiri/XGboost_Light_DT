{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b56bea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåº Classification: Iris Dataset\n",
      "\n",
      "üå≤ Random Forest Classifier Mode 1: {'n_estimators': 50, 'max_depth': 3, 'random_state': 0}\n",
      "Accuracy: 0.9111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       0.82      0.93      0.88        15\n",
      "   virginica       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.92      0.91      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n",
      "\n",
      "üå≤ Random Forest Classifier Mode 2: {'n_estimators': 100, 'max_depth': 5, 'random_state': 1}\n",
      "Accuracy: 0.9111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       0.82      0.93      0.88        15\n",
      "   virginica       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.92      0.91      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n",
      "\n",
      "üå≤ Random Forest Classifier Mode 3: {'n_estimators': 200, 'max_depth': None, 'random_state': 2}\n",
      "Accuracy: 0.9111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       0.82      0.93      0.88        15\n",
      "   virginica       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.92      0.91      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n",
      "\n",
      "üå≥ Decision Tree 1: {'max_depth': 3, 'random_state': 0}\n",
      "Accuracy: 0.9333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       0.88      0.93      0.90        15\n",
      "   virginica       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.93      0.93        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n",
      "\n",
      "üå≥ Decision Tree 2: {'max_depth': 5, 'criterion': 'entropy', 'random_state': 1}\n",
      "Accuracy: 0.8889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       0.81      0.87      0.84        15\n",
      "   virginica       0.86      0.80      0.83        15\n",
      "\n",
      "    accuracy                           0.89        45\n",
      "   macro avg       0.89      0.89      0.89        45\n",
      "weighted avg       0.89      0.89      0.89        45\n",
      "\n",
      "\n",
      "üå≥ Decision Tree 3: {'max_depth': None, 'random_state': 2}\n",
      "Accuracy: 0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       1.00      0.93      0.97        15\n",
      "   virginica       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "üè° model: California Housing Dataset\n",
      "\n",
      "üå≤ Random Forest Regressor\n",
      "Mean Squared Error: 0.2948\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
    "\n",
    "# ---------- Classification Models (Iris Dataset) ----------\n",
    "print(\"üåº Classification: Iris Dataset\")\n",
    "iris = load_iris()\n",
    "X_class, y_class = iris.data, iris.target\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n",
    "    X_class, y_class, test_size=0.3, stratify=y_class, random_state=42\n",
    ")\n",
    "\n",
    "# ----------------------------- Random Forest Classifier (Multiple) ---------------------------\n",
    "rf_modes = [\n",
    "    {\"n_estimators\": 50, \"max_depth\": 3, \"random_state\": 0},\n",
    "    {\"n_estimators\": 100, \"max_depth\": 5, \"random_state\": 1},\n",
    "    {\"n_estimators\": 200, \"max_depth\": None, \"random_state\": 2}\n",
    "]\n",
    "\n",
    "for i, mode in enumerate(rf_modes):\n",
    "    clf = RandomForestClassifier(**mode)\n",
    "    clf.fit(Xc_train, yc_train)\n",
    "    preds = clf.predict(Xc_test)\n",
    "    print(f\"\\nüå≤ Random Forest Classifier Mode {i+1}: {mode}\")\n",
    "    print(f\"Accuracy: {accuracy_score(yc_test, preds):.4f}\")\n",
    "    print(classification_report(yc_test, preds, target_names=iris.target_names))\n",
    "\n",
    "# -------------------------------  Decision Trees (Baseline Comparisons) -------------------------\n",
    "tree_modes = [\n",
    "    {\"max_depth\": 3, \"random_state\": 0},\n",
    "    {\"max_depth\": 5, \"criterion\": \"entropy\", \"random_state\": 1},\n",
    "    {\"max_depth\": None, \"random_state\": 2}\n",
    "]\n",
    "\n",
    "for i, mode in enumerate(tree_modes):\n",
    "    dt = DecisionTreeClassifier(**mode)\n",
    "    dt.fit(Xc_train, yc_train)\n",
    "    preds = dt.predict(Xc_test)\n",
    "    print(f\"\\nüå≥ Decision Tree {i+1}: {mode}\")\n",
    "    print(f\"Accuracy: {accuracy_score(yc_test, preds):.4f}\")\n",
    "    print(classification_report(yc_test, preds, target_names=iris.target_names))\n",
    "\n",
    "# ----------  Model (California Housing Dataset) ----------\n",
    "print(\"\\nüè° model: California Housing Dataset\")\n",
    "housing = fetch_california_housing()\n",
    "X_reg, y_reg = housing.data, housing.target\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "#-----------------------------  Random Forest Regressor ---------------------\n",
    "regressor = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "regressor.fit(Xr_train, yr_train)\n",
    "y_pred = regressor.predict(Xr_test)\n",
    "mse = mean_squared_error(yr_test, y_pred)\n",
    "print(f\"\\nüå≤ Random Forest Regressor\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
